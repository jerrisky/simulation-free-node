nohup: ignoring input
======== ğŸš€ Start Task: Movie ========

--- Fold 0 ---
Seed set to 0
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
Using total batch size 64 = 1 x 64
wandb: WARNING The anonymous setting has no effect and will be removed in a future version.
wandb: Tracking run with wandb version 0.23.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in logs/wandb/offline-run-20260105_102455-c8swu2er
[!] 0 parameters are freezed.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                               â”ƒ Type      â”ƒ Params â”ƒ Mode  â”ƒ FLOPs â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ task_criterion                     â”‚ MSELoss   â”‚      0 â”‚ train â”‚     0 â”‚
â”‚ 1  â”‚ label_ae_criterion                 â”‚ MSELoss   â”‚      0 â”‚ train â”‚     0 â”‚
â”‚ 2  â”‚ odeblock                           â”‚ ODEBlock  â”‚  462 K â”‚ train â”‚     0 â”‚
â”‚ 3  â”‚ odeblock.odefunc                   â”‚ MLPODEFuâ€¦ â”‚  462 K â”‚ train â”‚     0 â”‚
â”‚ 4  â”‚ odeblock.odefunc.fc1               â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 5  â”‚ odeblock.odefunc.fc2               â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 6  â”‚ odeblock.odefunc.fc3               â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 7  â”‚ odeblock.odefunc.non_linearity     â”‚ ReLU      â”‚      0 â”‚ train â”‚     0 â”‚
â”‚ 8  â”‚ odeblock.odefunc.tmlp_blocks       â”‚ ModuleLiâ€¦ â”‚  264 K â”‚ train â”‚     0 â”‚
â”‚ 9  â”‚ odeblock.odefunc.tmlp_blocks.0     â”‚ tMLPBlock â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 10 â”‚ odeblock.odefunc.tmlp_blocks.0.fc1 â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 11 â”‚ odeblock.odefunc.tmlp_blocks.1     â”‚ tMLPBlock â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 12 â”‚ odeblock.odefunc.tmlp_blocks.1.fc1 â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 13 â”‚ odeblock.odefunc.tmlp_blocks.2     â”‚ tMLPBlock â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 14 â”‚ odeblock.odefunc.tmlp_blocks.2.fc1 â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 15 â”‚ odeblock.odefunc.tmlp_blocks.3     â”‚ tMLPBlock â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 16 â”‚ odeblock.odefunc.tmlp_blocks.3.fc1 â”‚ Linear    â”‚ 66.0 K â”‚ train â”‚     0 â”‚
â”‚ 17 â”‚ in_projection                      â”‚ Linear    â”‚  478 K â”‚ train â”‚     0 â”‚
â”‚ 18 â”‚ out_projection                     â”‚ Linear    â”‚  1.3 K â”‚ train â”‚     0 â”‚
â”‚ 19 â”‚ label_projection                   â”‚ Linear    â”‚  1.5 K â”‚ train â”‚     0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 943 K                                                         
Non-trainable params: 0                                                         
Total params: 943 K                                                             
Total estimated model params size (MB): 3                                       
Modules in train mode: 20                                                       
Modules in eval mode: 0                                                         
Total FLOPs: 0                                                                  
 Epoch 0: val/avg_imp = -51.9667
 Details: Cheby=0.4293, Clark=2.0678, Canbe=4.4828, KL=28.9234, Cos=-0.5836, Inter=0.4154
 Epoch 33: val/avg_imp = -0.1476
 Details: Cheby=0.1315, Clark=0.5985, Canbe=1.1409, KL=0.1285, Cos=0.9161, Inter=0.8092
 Epoch 66: val/avg_imp = -0.1453
 Details: Cheby=0.1313, Clark=0.5974, Canbe=1.1390, KL=0.1278, Cos=0.9162, Inter=0.8095
 Epoch 99: val/avg_imp = -0.1502
 Details: Cheby=0.1317, Clark=0.5986, Canbe=1.1407, KL=0.1298, Cos=0.9154, Inter=0.8090
 Epoch 132: val/avg_imp = -0.1491
 Details: Cheby=0.1316, Clark=0.5986, Canbe=1.1410, KL=0.1293, Cos=0.9160, Inter=0.8092
 Epoch 166: val/avg_imp = -0.1483
 Details: Cheby=0.1315, Clark=0.5983, Canbe=1.1406, KL=0.1290, Cos=0.9160, Inter=0.8092
`Trainer.fit` stopped: `max_steps=10000` reached.
`weights_only` was not set, defaulting to `False`.
[!] Saved last checkpoint at ./logs/last_step=10000.ckpt
Epoch 169/-2 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 29/29 0:00:00 â€¢        61.32it/s v_num: u2er      
                                    0:00:00                    val/best_avg_imp:
                                                               -0.145           
wandb: 
wandb: Run history:
wandb:           epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        lr-AdamW â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:      test/Canbe â–‡â–â–‡â–ˆâ–†
wandb:      test/Cheby â–…â–â–ˆâ–‡â–†
wandb:      test/Clark â–‡â–â–ˆâ–ˆâ–†
wandb:     test/Cosine â–‡â–ˆâ–â–†â–†
wandb:      test/Inter â–„â–ˆâ–â–„â–„
wandb:         test/KL â–ƒâ–â–ˆâ–†â–…
wandb:  test/avg_imp_1 â–â–â–â–â–
wandb: test/avg_imp_10 â–â–â–â–â–
wandb:             +23 ...
wandb: 
wandb: Run summary:
wandb:           epoch 169
wandb:        lr-AdamW 0.0
wandb:      test/Canbe 1.14057
wandb:      test/Cheby 0.13154
wandb:      test/Clark 0.59828
wandb:     test/Cosine 0.91596
wandb:      test/Inter 0.80923
wandb:         test/KL 0.12895
wandb:  test/avg_imp_1 0
wandb: test/avg_imp_10 0
wandb:             +23 ...
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync logs/wandb/offline-run-20260105_102455-c8swu2er
wandb: Find logs at: logs/wandb/offline-run-20260105_102455-c8swu2er/logs
Traceback (most recent call last):
  File "/home/ubuntu/zxj/sfnode/auto_run_sfnode.py", line 179, in <module>
    run_experiment(args.dataset, args.device)
  File "/home/ubuntu/zxj/sfnode/auto_run_sfnode.py", line 98, in run_experiment
    print(f"Fold {fold} Imp: {imp:.4f}")
TypeError: unsupported format string passed to dict.__format__
